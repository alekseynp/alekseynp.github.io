<!DOCTYPE html>
<html lang="es">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="Aleksey Nozdrn-Plotnicki">

    <title>	Aleksey Nozdryn-Plotnicki
</title>

    <!-- Bootstrap Core CSS - Uses Bootswatch Flatly Theme: http://bootswatch.com/flatly/ -->
    <link href="/static/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="/static/css/freelancer.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="/static/fonts/font-awesome-4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

	<!-- RSS FEEDS -->

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-56820808-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-56820808-1');
    </script>


</head>

<body id="page-top" class="index">

<nav class="navbar navbar-default navbar-fixed-top">
    <div class="container">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Aleksey Nozdryn-Plotnicki</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
            	<li class="hidden">
                    <a href="#page-top"></a>
                </li>
                <li class="page-scroll">
                    <a href="index.html#portfolio">Projects</a>
                </li>
                <li class="page-scroll">
                    <a href="index.html#blog">Blog</a>
                </li>
                
            </ul>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container-fluid -->
</nav>
	

<header>
    <div class="container">
        <div class="row">
            <div class="col-lg-12">
                <div class="intro-text">
                    <span class="name">Paper Summary: PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</span>
                    <hr class="star-light">
                    2018-09-27
                </div>
            </div>
        </div>
    </div>
</header>    


<section>
    <div class="container">
        <div class="row">
            <article>
                <div class="content">
                    <style>
    .MathJax {
        font-size: 1em;
    }
</style>

<h2>Introduction</h2>
<p>This is summary of <a href="https://arxiv.org/abs/1612.00593">PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation</a> for the <a href="https://www.meetup.com/LearnDataScience/">Vancouver Data Science Reading Group</a></p>
<p>The paper authors are: Charles R. Qi, Hao Su, Kaichun Mo, Leonaidas J. Guibas</p>
<p>There's code!: <a href="https://github.com/charlesq34/pointnet">https://github.com/charlesq34/pointnet</a></p>
<p>There's a lot going on in this paper. I highlight the most important parts below:</p>
<ol>
<li>
<p>Deep Learning on Unordered Sets</p>
</li>
<li>
<p>Point Clouds</p>
</li>
<li>
<p>Architecture</p>
</li>
<li>
<p>Implementation</p>
</li>
<li>
<p>Why does it work on point clouds?</p>
</li>
<li>
<p>Other Comments</p>
</li>
</ol>
<p><br /></p>
<h2>Deep Learning on Unordered Sets</h2>
<p><strong>This is a powerful idea that is useful for anyone working in Machine Learning, not at all limited to point clouds or computer vision applications.</strong></p>
<p>In ML we should be very familiar with learning a function <span class="math">\(f(x)\rightarrow y\)</span> that takes some vector <span class="math">\(x\)</span> and creates a desired output <span class="math">\(y\)</span>, be it a regression task or a classification task. But what about a function on a set <span class="math">\(f(\left \{x_1,x_2,...,x_n\right \})\rightarrow y\)</span>? The critical detail is that this function should be invariant to permutations of its inputs, <span class="math">\(f(\left \{x_1,x_2,...,x_n\right \})= f(\left \{x_n,x_2,...,x_1\right \})\)</span>, because indeed the set's meaning has not changed.</p>
<p>A typical ML paradigm expects a single vector input. Your options are:</p>
<ol>
<li>
<p>Sort input into a canonical order. Invent some ordering and concatenate the vectors to a single <span class="math">\(x\)</span>. This is clearly suboptimal as our model will not understand the shared nature of elements of <span class="math">\(x\)</span> and will treat each as a unique feature.</p>
</li>
<li>
<p>Augment the training data with all kinds of permutations. This is an ugly hack, and utterly impossible if the set is large.</p>
</li>
<li>
<p>The author's approach.</p>
</li>
</ol>
<p>The idea is to:</p>
<ol>
<li>
<p>Create an <span class="math">\(h(x)\)</span> and apply it to every element of the set.</p>
</li>
<li>
<p>Apply a symmetric function <span class="math">\(g(h(x_1),h(x_2),...,h(x_n))\rightarrow y\)</span>. The magically simple fact is that <em>mean</em> and <em>max</em> are symmetric functions, and therefore <code>max_pool</code> and <code>average_pool</code> are symmetric functions.</p>
</li>
</ol>
<p>The "Deep Learning" comes in when the authors implement the <span class="math">\(h()\)</span> as a multi-layer perceptron (deep neural network) and implement <span class="math">\(g()\)</span> as a <code>max</code> followed by another multi-layer perceptron.</p>
<p>Why this works on point clouds is hard to wrap your head around. Suppose instead we wanted to take a team of developers and predict if they are likely to ship a release on time. We apply <span class="math">\(h()\)</span> to each developer to compute a feature vector <span class="math">\(h(x_i)\)</span> that describes the developer. If we apply a feature-wise <code>max</code> across the feature vectors, we get a single feature vector signature for the development team that did not depend on the set order. Finally we process that team feature to make our final prediction. <span class="math">\(g(max(\left \{h(x_1),h(x_2),...,h(x_n)\right \}))\rightarrow y\)</span>.</p>
<p>In the Zillow Kaggle competition I experimented with PointNets. When predicting the value of a house, we could use statistical aggregate metrics about the neighbourhood it falls in, but we could also consider the k nearest houses as an unordered set that we could use to make predictions from. In a sense, the statistical measures like mean, median, standard deviation, etc. are engineered features and a DNN learning on the set has a chance of learning its own features. That may sound esoteric, but it is the classic story when using DNNs for computer vision applications vs. how those tasks were solved in the past.</p>
<p><br /></p>
<h2>Point Clouds</h2>
<p>Classifying 2D images has been done to death, but what about 3D data? Most of the 3D graphics we see in everyday life are triangular meshes. Millions of triangles rendered on a screen to make your video game or movie. However, the typical data format that comes from a 3D sensor is a point cloud. Some kind of sensor measures the 3D environment and generates an unordered list of <span class="math">\((x, y, z)\)</span> coordinates. If you look at the raw data it doesn't look like much, but if you did a <code>plot3d</code> on it, you would be able to see it and guess what it is.</p>
<p>In particular the authors run experiments on <em>ModelNet40</em> a benchmark dataset not unlike CIFAR-10 or CIFAR-100. The native data format for ModelNet40 is actually a triangular mesh, so converting it to point clouds is a little artificial, but it makes for a worthwhile benchmark to do research against. The authors achieve very good results on the benchmark with their approach.</p>
<p><br /></p>
<h2>Architecture</h2>
<p>Their architecture is at the top of page 3. For a first time reader of this paper, the "input transform" and "feature transform" from the "joint alignment networks" are best ignored and not important. They contribute very little to performance in the end. One should also understand the classification case before studying the segmentation.</p>
<p>The basic classification architecture is:</p>
<ol>
<li>
<p>Input points of shape <code>(n, 3)</code>.</p>
</li>
<li>
<p>MLP fully connected deep neural network with sizes 64, 64, 64, 128, 1024 applied to each point individually mapping <span class="math">\(R^3\rightarrow R^{1024}\)</span></p>
</li>
<li>
<p>Max pool from shape <code>(n, 1024)</code> to a feature vector of shape <code>(1024,)</code> </p>
</li>
<li>
<p>MLP fully connected with size 512, 256, k where k is the number of classes mapping <span class="math">\(R^{1024}\rightarrow R^k\)</span></p>
</li>
</ol>
<p><br /></p>
<h2>Implementation</h2>
<p>It's worth seeing their clever implementation <a href="https://github.com/charlesq34/pointnet/blob/master/models/pointnet_cls.py">here</a></p>
<ol>
<li>
<p>An input batch is prepared as an "image" of shape <code>(batch_size, 1, n, 3)</code> (channels first notation)</p>
</li>
<li>
<p>A 2D convolution with 64 kernels of size <code>(1, 3)</code> with no padding is applied. This is equivalent to applying the same 64 neuron hidden layer to every row of the "image" or in fact the same 64 neuron hidden layer to every point in the cloud. The output is of shape <code>(batch_size, 64, n, 1)</code> or an "image" with 64 channels, 1 pixel wide and n pixels tall.</p>
</li>
<li>
<p>After that 2D convolutions with filters 64, 64, 128, and 1024 of size <code>(1,1)</code> process every point individually. The net effect is that the same MLP(64, 64, 64, 128, 1024), our <span class="math">\(h()\)</span> is applied to every point.</p>
</li>
<li>
<p>Finally a global max pool reduces <code>(batch_size, 1024, n, 1)</code> to <code>(batch_size, 1024)</code> and fully connected layers are used for classification.</p>
</li>
</ol>
<p>You could also implement this as 1D convolutions starting with a input of shape <code>(batch_size, 3, n)</code> (channels first notation) and indeed I do in my own work.</p>
<p><br /></p>
<h2>Why does it work on point clouds?</h2>
<p>Each of the 1024 output features from the <span class="math">\(h()\)</span> can be thought of as point detectors. These numbers are derived only from 3 inputs! Some of these feature are excited by points that are very far from the origin. Some are excited by points below the origin. Some are excited by points in an arc in front of the origin. Before the max pool, each input point has excited some of the feature space elements, and after the max pool we have a summary of how the point cloud excited the features. A summary of where the points are.</p>
<p>Maybe the visualizations in figure 19 on page 15 would help.</p>
<p><br /></p>
<h2>Other Comments</h2>
<h3>Extensions</h3>
<p>The major limitation of their architecture is that it makes no use of local structure and cannot learn hierarchical features. There is a <a href="https://arxiv.org/abs/1706.02413">
PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space</a> that is worth looking up.</p>
<p><br /></p>
<h3>Comparison to VoxNet</h3>
<p>Why, in Supplementary B, do they make a point of demonstrating their superior robustness vs. VoxNet?</p>
<p>Voxels are an alternative approach for classifying 3D objects. In the case of ModelNet40, the triangular meshes are converted to a 3D grid where each cell in the grid is occupied or not. Think about converting the 3D models to LEGO. After that, 3D CNNs can be applied in an analogous way to how 2D CNNs are applied for image classification. Converting the ModelNet40 triangular meshes to point clouds for this paper was an unfortunate necessity, but it's worth noting that voxel based approaches are also inelegant. Ultimately we should strive to process data in its native format. In the case of voxels, they are complete garbage if your input data is a sparse point cloud, or a point cloud that is in places sparse. This is because a sparse pount cloud converted to a voxel grid will provide only a few occupied cells. A 3DNN will then be mostly convolving across zeros and will struggle to learn anything. It's worth noting that this sparseness is actually a <em>very</em> common phenomenon in real world point clouds. They tend to be stupidly dense in some areas and frustratingly sparse in others as a consequence of the technology that gathers them.</p>
<p><br /></p>
<h3>Effect of Bottleneck Dimension and Number of Input Points</h3>
<p>The Supplementary F section is interesting to a practitioner and figure 15 in particular:</p>
<ul>
<li>
<p>They achieve incredible performance with only 64 input points. A human looking at a <code>Plot3D</code> with only 64 points would struggle to classify the objects. In that sense, this network is superhuman.</p>
</li>
<li>
<p>It is important that the feature size be relatively large. The "bottleneck size" that is generally presented as 1024 in the architecture. The PointNet is roughly equivalent to a 7 layer CNN operating on a 32x32x3 image. 1024 would be very large in that case. This highlights the brute force nature of this architecture and the lack of local structure/hierarchical feature exploitation. The message for a practitioner is to make this layer larger than you might otherwise.</p>
</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                </div>
            </article>
        </div>
    </div>
</section>

	

<!-- Footer -->
    <footer class="text-center">
        <div class="footer-below">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        Copyright &copy; Aleksey Nozdryn-Plotnicki <script>document.write(new Date().getFullYear())</script>
                    </div>
                </div>
            </div>
        </div>
    </footer>
<!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
<div class="scroll-top page-scroll visible-xs visble-sm">
    <a class="btn btn-primary" href="#page-top">
        <i class="fa fa-chevron-up"></i>
    </a>
</div>
	
	


	
		<!-- script is a local library -->
			<script src="/static/js/jquery-1.11.0.js"></script>
		
	
		<!-- script is a local library -->
			<script src="/static/js/bootstrap.min.js"></script>
		
	
		<!-- script is a url -->
			<script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
		
		
	
		<!-- script is a local library -->
			<script src="/static/js/classie.js"></script>
		
	
		<!-- script is a local library -->
			<script src="/static/js/cbpAnimatedHeader.js"></script>
		
	
		<!-- script is a local library -->
			<script src="/static/js/jqBootstrapValidation.js"></script>
		
	
		<!-- script is a local library -->
			<script src="/static/js/contact_me.js"></script>
		
	
		<!-- script is a local library -->
			<script src="/static/js/freelancer.js"></script>
		
	

</body>

</html>